{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastLSTM:\n",
    "    def __init__(self, random_seed:int = 1234):\n",
    "        self.random_seed = random_seed\n",
    "    \n",
    "def reshape_dataset(self, df: pd.DataFrame) -> np.array:\n",
    "    if \"y\" in df.columns:\n",
    "        df = df.drop(columns=[\"y\"]).assign(y=df[\"y\"])\n",
    "    else:\n",
    "        raise KeyError(\"Not found target column 'y' in dataset.\")\n",
    "    \n",
    "    dataset = df.values.reshape(df.shape)\n",
    "    return dataset\n",
    "    \n",
    "ForecastLSTM.reshape_dataset = reshape_dataset\n",
    "    \n",
    "def split_sequences(\n",
    "    self, dataset: np.array, seq_len: int, steps: int, single_output: bool\n",
    ") -> tuple:\n",
    "    \n",
    "    x,y = list(), list()\n",
    "    for i, _ in enumerate(dataset):\n",
    "        idx_in = i + seq_len\n",
    "        idx_out = idx_in + steps\n",
    "        if idx_out > len(dataset):\n",
    "            break\n",
    "        seq_x = dataset[i:idx_in, :-1]\n",
    "        if single_output:\n",
    "            seq_y = dataset[idx_out - 1 : idx_out, -1]\n",
    "        else:\n",
    "            seq_y = dataset[idx_in:idx_out, -1]\n",
    "            \n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid_dataset(\n",
    "    self,\n",
    "    df: pd.DataFrame,\n",
    "    seq_len:int,\n",
    "    steps: int,\n",
    "    single_output: bool,\n",
    "    validation_split: float=0.3,\n",
    "    verbose: bool = True,\n",
    ") -> tuple:\n",
    "    dataset = self.reshape_dataset(df=df)\n",
    "    \n",
    "    x,y = self.split_sequences(\n",
    "        dataset = dataset,\n",
    "        seq_len = seq_len,\n",
    "        steps = steps,\n",
    "        single_output = single_output,\n",
    "    )\n",
    "    \n",
    "    dataset_size = len(x)\n",
    "    train_size = int(dataset_size * (1 - validation_split))\n",
    "    x_train, y_train = x[:train_size, :], y[:train_size, :]\n",
    "    x_val, y_val = x[train_size:, :], y[train_size:, :]\n",
    "    if verbose:\n",
    "        print(f\" >>> x_train : {x_train.shape}\")\n",
    "        print(f\" >>> y_train : {y_train.shape}\")\n",
    "        print(f\" >>> x_val : {x_val.shape}\")\n",
    "        print(f\" >>> y_val : {y_val.shape}\")\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "ForecastLSTM.split_train_valid_dataset = split_train_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_lstm_model(\n",
    "    self,\n",
    "    seq_len: int,\n",
    "    n_features: int,\n",
    "    lstm_units: list,\n",
    "    learning_rate: float,\n",
    "    dropout: float,\n",
    "    steps: int,\n",
    "    metrics: str,\n",
    "    single_output: bool,\n",
    "    last_lstm_return_sequences: bool = False,\n",
    "    dense_units: list = None,\n",
    "    activation: str = None,\n",
    "):\n",
    "    tf.random.set_seed(self.random_seed)\n",
    "    model = Sequential()\n",
    "    \n",
    "    if len(lstm_units) > 1:\n",
    "        model.add(\n",
    "            LSTM(\n",
    "                units=lstm_units[0],\n",
    "                activation=activation,\n",
    "                return_sequences=True,\n",
    "                input_shape = (seq_len, n_features),\n",
    "            )\n",
    "        )\n",
    "        lstm_layers = lstm_units[1:]\n",
    "        for i, n_units in enumerate(lstm_layers, start=1):\n",
    "            if i == len(lstm_layers):\n",
    "                if single_output:\n",
    "                    return_sequences = False\n",
    "                else:\n",
    "                    return_sequences = last_lstm_return_sequences\n",
    "                model.add(\n",
    "                    LSTM(\n",
    "                        units=n_units,\n",
    "                        activation=activation,\n",
    "                        return_sequences=return_sequences,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                model.add(\n",
    "                    LSTM(\n",
    "                        units=n_units,\n",
    "                        activation=activation,\n",
    "                        return_sequences=True,\n",
    "                    )\n",
    "                )\n",
    "    else:    \n",
    "        # LSTM -> Dense(steps)\n",
    "        if single_output:\n",
    "            return_sequences = False\n",
    "        else:\n",
    "            return_sequences = last_lstm_return_sequences\n",
    "        model.add(\n",
    "            LSTM(\n",
    "                units=lstm_units[0],\n",
    "                activation=activation,\n",
    "                return_sequences=return_sequences,\n",
    "                input_shape=(seq_len, n_features),\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    if single_output:  # Single Step, Direct Multi Step\n",
    "        if dense_units:\n",
    "            for n_units in dense_units:\n",
    "                model.add(Dense(units=n_units, activation=activation))\n",
    "        if dropout > 0:\n",
    "            model.add(Dropout(rate=dropout))\n",
    "        model.add(Dense(1))\n",
    "    else:  # Multiple Output Step\n",
    "        if last_lstm_return_sequences:\n",
    "            model.add(Flatten())\n",
    "        if dense_units:\n",
    "            for n_units in dense_units:\n",
    "                model.add(Dense(units=n_units, activation=activation))\n",
    "        if dropout > 0:\n",
    "            model.add(Dropout(rate=dropout))\n",
    "        model.add(Dense(units=steps))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=MSE, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "ForecastLSTM.build_and_compile_lstm_model = build_and_compile_lstm_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lstm(\n",
    "    self,\n",
    "    df: pd.DataFrame,\n",
    "    steps: int,\n",
    "    lstm_units: list,\n",
    "    activation: str,\n",
    "    dropout: float = 0,\n",
    "    seq_len: int = 16,\n",
    "    single_output: bool = False,\n",
    "    epochs: int = 200,\n",
    "    batch_size: int = None,\n",
    "    steps_per_epoch: int = None,\n",
    "    learning_rate: float = 0.001,\n",
    "    patience: int = 10,\n",
    "    validation_split: float = 0.3,\n",
    "    last_lstm_return_sequences: bool = False,\n",
    "    dense_units: list = None,\n",
    "    metrics: str = \"mse\",\n",
    "    check_point_path: str = None,\n",
    "    verbose: bool = False,\n",
    "    plot: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    LSTM 기반 모델 훈련을 진행한다.\n",
    "\n",
    "    :param df: DataFrame for model train.\n",
    "    :param steps: Length to predict.\n",
    "    :param lstm_units: LSTM, Dense Layers\n",
    "    :param activation: Activation function for LSTM, Dense Layers.\n",
    "    :param dropout: Dropout ratio between Layers.\n",
    "    :param seq_len: Length of sequences. (Look back window size)\n",
    "    :param single_output: Select whether 'y' is a continuous value or a single value.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(self.random_seed)\n",
    "    tf.random.set_seed(self.random_seed)\n",
    "\n",
    "    # 훈련, 검증 데이터셋 생성\n",
    "    (\n",
    "        self.X_train,\n",
    "        self.y_train,\n",
    "        self.X_val,\n",
    "        self.y_val,\n",
    "    ) = self.split_train_valid_dataset(\n",
    "        df=df,\n",
    "        seq_len=seq_len,\n",
    "        steps=steps,\n",
    "        validation_split=validation_split,\n",
    "        single_output=single_output,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    # LSTM 모델 생성\n",
    "    n_features = df.shape[1] - 1\n",
    "    self.model = self.build_and_compile_lstm_model(\n",
    "        seq_len=seq_len,\n",
    "        n_features=n_features,\n",
    "        lstm_units=lstm_units,\n",
    "        activation=activation,\n",
    "        learning_rate=learning_rate,\n",
    "        dropout=dropout,\n",
    "        steps=steps,\n",
    "        last_lstm_return_sequences=last_lstm_return_sequences,\n",
    "        dense_units=dense_units,\n",
    "        metrics=metrics,\n",
    "        single_output=single_output,\n",
    "    )\n",
    "\n",
    "    # 모델 적합 과정에서 best model 저장\n",
    "    if check_point_path is not None:\n",
    "        # create checkpoint\n",
    "        checkpoint_path = f\"checkpoint/lstm_{check_point_path}.h5\"\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            filepath=checkpoint_path,\n",
    "            save_weights_only=False,\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\",\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        rlr = ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=patience, verbose=verbose\n",
    "        )\n",
    "        callbacks = [checkpoint, EarlyStopping(patience=patience), rlr]\n",
    "    else:\n",
    "        rlr = ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=patience, verbose=verbose\n",
    "        )\n",
    "        callbacks = [EarlyStopping(patience=patience), rlr]\n",
    "\n",
    "    # 모델 훈련\n",
    "    self.history = self.model.fit(\n",
    "        self.X_train,\n",
    "        self.y_train,\n",
    "        batch_size=batch_size,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=(self.X_val, self.y_val),\n",
    "        epochs=epochs,\n",
    "        use_multiprocessing=True,\n",
    "        workers=8,\n",
    "        verbose=verbose,\n",
    "        callbacks=callbacks,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    # 훈련 종료 후 best model 로드\n",
    "    if check_point_path is not None:\n",
    "        self.model.load_weights(f\"checkpoint/lstm_{check_point_path}.h5\")\n",
    "\n",
    "    # 모델링 과정 시각화\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(self.history.history[f\"{metrics}\"])\n",
    "        plt.plot(self.history.history[f\"val_{metrics}\"])\n",
    "        plt.title(\"Performance Metric\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(f\"{metrics}\")\n",
    "        if metrics == \"mape\":\n",
    "            plt.axhline(y=10, xmin=0, xmax=1, color=\"grey\", ls=\"--\", alpha=0.5)\n",
    "        plt.legend([\"Train\", \"Validation\"], loc=\"upper right\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "ForecastLSTM.fit_lstm = fit_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_validation_dataset(self) -> pd.DataFrame:\n",
    "    # 검증 데이터셋의 실제 값(y)과, 예측 값(yhat)을 저장할 리스트 생성\n",
    "    y_pred_list, y_val_list = list(), list()\n",
    "    \n",
    "    # 훈련된 모델로 validation dataset에 대한 예측값 생성\n",
    "    for x_val, y_val in zip(self.X_val, self.y_val):\n",
    "        x_val = np.expand_dims(\n",
    "            x_val, axis=0\n",
    "        )  # (seq_len, n_features) -> (1, seq_len, n_features)\n",
    "        y_pred = self.model.predict(x_val)[0]\n",
    "        y_pred_list.extend(y_pred.tolist())\n",
    "        y_val_list.extend(y_val.tolist())\n",
    "    return pd.DataFrame({\"y\": y_val_list, \"yhat\": y_pred_list})\n",
    "\n",
    "\n",
    "ForecastLSTM.forecast_validation_dataset = forecast_validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df_fcst: pd.DataFrame) -> dict:\n",
    "    true = df_fcst[\"y\"]\n",
    "    pred = df_fcst[\"yhat\"]\n",
    "\n",
    "    mae = (true - pred).abs().mean()\n",
    "    mape = (true - pred).abs().div(true).mean() * 100\n",
    "    mse = ((true - pred) ** 2).mean()\n",
    "    return {\n",
    "        \"mae\": mae,\n",
    "        \"mape\": mape,\n",
    "        \"mse\": mse,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'pandas._libs.properties.AxisProperty' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## 1) Train, Test 데이터 분리\u001b[39;00m\n\u001b[0;32m      2\u001b[0m cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2022-01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m df_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame[\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m]\n\u001b[0;32m      4\u001b[0m df_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame[pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m cutoff]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m## 2) Sequence Length, 예측 기간(Step), Single Output 여부 등 정의\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'pandas._libs.properties.AxisProperty' and 'str'"
     ]
    }
   ],
   "source": [
    "## 1) Train, Test 데이터 분리\n",
    "cutoff = \"2022-01-01\"\n",
    "df_train = pd.DataFrame[pd.DataFrame.index < cutoff]\n",
    "df_test = pd.DataFrame[pd.DataFrame.index >= cutoff]\n",
    "\n",
    "## 2) Sequence Length, 예측 기간(Step), Single Output 여부 등 정의\n",
    "seq_len = 5  # 과거 5주의 데이터를 feature로 사용\n",
    "steps = 5  # 향후 5주의 y를 예측\n",
    "single_output = False  # 향후 5주차의 시점만이 아닌, 1~5주 모두 예측\n",
    "metrics = \"mse\"  # 모델 성능 지표\n",
    "\n",
    "## 3) LSTM 하이퍼파라미터 정의\n",
    "lstm_params = {\n",
    "    \"seq_len\": seq_len,\n",
    "    \"epochs\": 300,  # epochs 반복 횟수\n",
    "    \"patience\": 30,  # early stopping 조건\n",
    "    \"steps_per_epoch\": 5,  # 1 epochs 시 dataset을 5개로 분할하여 학습\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"lstm_units\": [64, 32],  # Dense Layer: 2, Unit: (64, 32)\n",
    "    \"activation\": \"relu\",\n",
    "    \"dropout\": 0,\n",
    "    \"validation_split\": 0.3,  # 검증 데이터셋 30%\n",
    "}\n",
    "\n",
    "## 4) 모델 훈련\n",
    "fl = ForecastLSTM()\n",
    "fl.fit_lstm(\n",
    "    df=df_train,\n",
    "    steps=steps,\n",
    "    single_output=single_output,\n",
    "    metrics=metrics,\n",
    "    **lstm_params,\n",
    ")\n",
    "\n",
    "## 5) Validation dataset 예측 성능\n",
    "df_fcst_val = fl.forecast_validation_dataset()\n",
    "val_loss = calculate_metrics(df_fcst=df_fcst_val)[metrics]\n",
    "print(f\"{metrics} of validation dataset: {val_loss.round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
